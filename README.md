# Hallu-PI

The code and datasets of our **ACM MM 2024** paper "Hallu-PI: Evaluating Hallucination in Multi-modal Large Language Models within Perturbed Inputs".

![ACMMM 2024](https://img.shields.io/badge/ACMMM-2024-blue.svg?style=plastic)
![Multi-modal Large
Language Models](https://img.shields.io/badge/MultiModalLargeLanguage-Models-green.svg?style=plastic)
![Hallucination Evaluation](https://img.shields.io/badge/Hallucination-Evaluation-orange.svg?style=plastic)
![Perturbed Inputs](https://img.shields.io/badge/Perturbed-Inputs-yellow.svg?style=plastic)


<div style="text-align:center">
  <img src="assets/perturbed_examples.png" style="width:100%"/>
  <p><em>Some examples of hallucinations in MLLMs with perturbed inputs (such as image concatenation, image cropping, and
prompt misleading). Text highlighted in green and red represents correct and hallucinatory content, respectively.</em></p>
</div>

**We are currently organizing our code and data and will release them as soon as possible. Please stay tuned**.
